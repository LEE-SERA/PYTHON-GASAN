# -*- coding: utf-8 -*-
"""CNN_MNIST_classification_이세라.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XZBns70g7uVnrJMBgv0hHro5mHU0HKyJ
"""

#CNN(convolutional Neural Network(CNN))
#영상으로부터 특정 feature를 추출하기위한 필터를 구현할때 사용
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from keras.utils import np_utils
from tensorflow.keras.layers import Flatten,Activation
from tensorflow.keras.layers import Dense,MaxPool2D, Conv2D, InputLayer


TOTAL_CLASS = 10
my_sample =5
MY_EPOCH =10
MY_BATCH =200

(X_train,Y_train),(X_test,Y_test) =mnist.load_data()
print('=====Data Shaping Info=====')
print('X train shape:',X_train.shape)
print('Y train shape:',Y_train.shape)
print('X test shape:',X_test.shape)
print('Y test shape:',Y_test.shape)

print('=====Sample Data(raw)======')
sample = Y_train[my_sample]
print('This is a', sample)

print(X_train[sample])
plt.imshow(X_train[my_sample])

unique, counts =np.unique(Y_train,return_counts =True)
print('=====Number Categorical of data in the training set')
for i in range(TOTAL_CLASS):
  print('label',unique[i],':',counts[i])

nique, counts =np.unique(Y_test,return_counts =True)
print('=====Number Categorical of data in the test set=====')
for i in range(TOTAL_CLASS):
  print('label',unique[i],':',counts[i])

X_train =X_train /255.0
X_test =X_test/255.0

X_train = X_train.reshape(X_train.shape[0],28,28,1)
X_test = X_test.reshape(X_test.shape[0],28,28,1)
Y_train = np_utils.to_categorical(Y_train,TOTAL_CLASS)
Y_test = np_utils.to_categorical(Y_test,TOTAL_CLASS)

print('======Data Shaping info =====')
print('X train shape:', X_train.shape)
print('Y train shape:', Y_train.shape)
print('X test shape:', X_test.shape)
print('Y test shape:', Y_test.shape)

model = Sequential()
model.add(InputLayer(input_shape = (28,28,1)))
model.add(Conv2D(32,kernel_size = (3,3),padding ='same',activation = 'relu'))
model.add(MaxPool2D(padding ='same',pool_size =(2,2)))
model.add(Conv2D(32,kernel_size = (3,3),padding ='same',activation = 'relu'))
model.add(MaxPool2D(padding ='same',pool_size =(2,2)))
model.add(Flatten())
model.add(Dense(128,activation ='relu'))
model.add(Dense(TOTAL_CLASS,activation  ='softmax'))
model.summary()

sample = X_train[my_sample]
sample = sample.reshape(1,28,28,1)
pred = model.predict(sample)
print('Prediction before learning:',np.argmax(pred),'\n')
print('Label is:',np.argmax(Y_train[my_sample]),'\n')

model.compile(optimizer = 'adam',loss='categorical_crossentropy',
              metrics = ['accuracy'])
history = model.fit(X_train,Y_train,
          epochs =MY_EPOCH,
          batch_size =MY_BATCH,
          verbose =1)
score =model.evaluate(X_test,Y_test,verbose =0)
print(score)





from sklearn.metrics import confusion_matrix
answer = np.argmax(Y_test,axis = 1)
pred =model.predict(X_test)
pred =np.argmax(pred,axis =1)
print('=====confusion matrix=====')
print(confusion_matrix(answer,pred))

from sklearn.metrics import f1_score
print('F1 score:',f1_score(answer,pred,average ='micro'))

my_sample = 212
sample = X_train[my_sample]
sample = sample.reshape(1,28,28,1)
pred = model.predict(sample)
print('Prediction after learning:',np.argmax(pred),'\n')
print('Label is:',np.argmax(Y_train[my_sample]),'\n')









































